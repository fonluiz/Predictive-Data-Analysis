---
title: "Lab 2 - Parte 2: Regressão linear para explicar desempenho acadêmico"
author: "Luiz Fonseca"
date: "26 de novembro de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

setwd("/home/luiz/Faculdade/Predictive-Data-Analysis/2nd lab/")
```

Primeiro vamos carregar os dados e bibliotecas que serão utilizados.

```{r, results='hide', message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(reshape2)
library(car)
library(leaps)

alunos.graduados <- read.csv("../data/graduados.csv")
```

## Entendendo o problema e os dados

Os dados são sobre alunos graduados do curso de Ciência da Computação da Universidade Federal de Campina Grande. Cada linha do data frame alunos.graduados representa o desempenho de um aluno em uma determinada disciplina. A tarefa é verificar se é possível prever, utilizando regressão linear múltipla, o desempenho final do aluno no curso (variável cra) a partir de seu desempenho nos dois primeiros semestres do curso.

## Tratando os dados

O arquivo original não está no formato ótimo para usármo-lo como entrada da função que gera um modelo linear. Abaixo, encontra-se o passo a passo para derivarmos um dataframe que podemos utilizar como entrada da função.

```{r, message=FALSE}
# Retira os valores NA das médias
alunos.graduados <- alunos.graduados %>% 
  arrange(matricula) %>%
  filter(!is.na(media))

# Calcula o CRA de cada aluno
graduados.cra <- alunos.graduados %>%
  group_by(matricula) %>%
  mutate(cra.contrb = media*creditos) %>%
  summarise(cra = round(sum(cra.contrb)/sum(creditos), 2))

disciplinas.iniciais <- c(
  "Cálculo Diferencial e Integral I",
  "Álgebra Vetorial e Geometria Analítica",
  "Leitura e Produção de Textos",
  "Programação I",
  "Introdução à Computação",
  "Laboratório de Programação I",
  "Cálculo Diferencial e Integral II",
  "Matemática Discreta",
  "Programação II",
  "Teoria dos Grafos",
  "Fundamentos de Física Clássica",
  "Laboratório de Programação II"
  )

# Transforma o dataframe em um formato ideal para ser utilizado como entrada do modelo
graduados.model.input <- alunos.graduados %>%
  filter(disciplina %in% disciplinas.iniciais) %>%
  group_by(matricula,disciplina)  %>%
  filter(media == max(media)) %>%
  ungroup() %>%
  select(matricula,disciplina,media) %>% 
  mutate(disciplina = as.factor(gsub(" ",".",disciplina))) %>%
  dcast(matricula ~ disciplina, mean) %>%
  merge(graduados.cra)
```

## Questionamentos
<ol>
<li> <b> Um modelo de regressão múltipla com todas as variáveis é plausível para explicar a variação em y? Em que grau? </b> </li>

```{r}
cra.model.fit <- lm(formula = cra ~ . -matricula, graduados.model.input, na.action = na.omit)
summary(cra.model.fit)
```

Vamos analisar cada coeficiente e estatística do modelo para termos uma noção geral. A estatística F nos dá uma ideia sobre o teste de hipóteses feito para verificar se pelo menos um dos coeficientes das variáveis preditoras é diferente de 0, isto é, se há pelo menos uma variável preditora que está relacionada com o a variável que se quer prevê, para este caso, o cra. Como o valor da estatística F é maior que 1 e o tamanho da amostra (n = 105) é consideravelmente maior que o número de preditores (p = 12), podemos inferir que há sim uma relação entre pelo menos uma das variáveis de entrada e a variável alvo. Isso também pode ser verificado olhando os coeficientes das variáveis de entrada, que são todos diferentes de 0.

Tendo verificado que as variáveis de entrada estão relacionadas com a variável alvo, agora podemos olhar para os p-valores de cada variável preditora. O p valor é uma probabilidade que nos fornece evidências para a hipótese nula. Um p-valor menor que 0,05 é considerado bom e indica que há fortes evidências de que a variávelse encaixa para o modelo. Um pvalor maior que 0,05 é considerado alto e indica que talvez a variável não se adeque ao modelo.

No modelo gerado com todas as variáveis, a maioria dos p-valores das variáveis está acima do treshold, que é 0,05, isso indica que talvez seja necessário retirar algumas variáveis que não fazem sentido para o modelo de regressão.

Um coeficiente que merece destaque é o r² ajustado. Para o modelo gerado, o R² ajustado, que mede o quão bem o modelo explica a variabilidade dos dados com relação a média da variável observada, é cerca de 0.6473 e isso significa que o modelo consegue exlicar a maior parte dos dados. Talvez esse valor não seja adequado para realizar uma predição, mas como há muita incosistência nos dados e o objetivo aqui não é realizar a predição com uma acurácia alta, o valor já está satisfatório.

<li><b>Todas as variáveis são úteis para o modelo de regressão?</b></li>

Para responder essa pergunta, iremos executar a tarefa conhecida como <i> seleção de variáveis </i>, que consiste em diagnosticar quais preditores estão associados com a resposta e quais podem ser descartados. Existem vários algoritmos de seleção de váriáveis: forward selection, backward selection, mixed selection, busca exaustiva, entre outros. Utilizarei o pacote leaps, que fornece métodos para executar vários tipos de seleção. O método utilizada é a busca exaustiva (exhaustive search), que irá procurar o melhor modelo dentre todos os possíveis.

```{r}
# library(leaps)
regsubsets.out <-
    regsubsets(cra ~ . -matricula,
               data = graduados.model.input,
               nbest = 1,       # 1 único modelo para cada cojunto de preditores
               nvmax = NULL,    # NULL para não haver limite no número de variáveis preditoras
               force.in = NULL, force.out = NULL,
               method = "exhaustive")

summary.out <- summary(regsubsets.out)
summary.out
```

Quando executamos summary(regsubsets.out), nos é mostrado o melhor modelo para cada tamanho de subconjunto de variáveis. Para este caso, a saída nos mostrará o melhor modelo utilizando apenas uma variável, o melhor modelo utilizando 2 variáveis e assim continua até todas as doze variáveis. O melhor modelo é definido em termos de maior R² ajustado e p-valores satisfatórios para as variáveis preditoras. Nos resta saber qual desses doze modelos representa o melhor modelo.

```{r}
# Qual dos doze modelos contém o melhor r² ajustado
which.max(summary.out$adjr2)
# Quais variáveis estão presentes nesse modelo
summary.out$which[6,]
```

Com isso descobrimos que o melhor modelo é aquele que contem apenas seis variáveis preditoras. Então, a partir destas seis variáveis, definiremos um novo modelo. 

```{r}
graduados.best.input <- graduados.model.input %>%
  dplyr::select(
    Álgebra.Vetorial.e.Geometria.Analítica, Introdução.à.Computação,
    Leitura.e.Produção.de.Textos, Matemática.Discreta, Programação.II,
    Teoria.dos.Grafos, cra, matricula
  )

cra.best.fit <- lm(formula = cra ~ . -matricula, graduados.best.input)
summary(cra.best.fit)
```

<li><b> Se a resposta para a pergunta anterior foi não, construa um novo modelo sem essas variáveis e o compare ao modelo com todas as variáveis (e.g. em termos de R2 e RSE). </b> </li>

Agora vamos comparar os dois modelos encontrados: o modelo com todas as variáveis e o modelo com seis variáveis apenas. O primeiro modelo possui o maior r² ajustado, 0.6473 contra 0.6075, do segundo modelo. O primeiro modelo possui um RSE menor do que o segundo, 0.5046 contra 0.526. 

O r² é o quadrado da correlação entre a variável de resposta e o modelo linear ajustado - Cor(Y, Ŷ )² -  e mede a fração de variância explicada. Poderíamos pensar que o primeiro modelo é melhor porque seu r² é maior e, portanto, ele explicaria melhor a variabilidade dos dados, mas isso não é verdade. Acontece que o r² irá sempre aumentar ao incluir novas variáveis no modelo, mesmo aquelas que estão fracamente associadas com a variável de resposta, ou seja, possuem p-valor alto. Isso se deve ao fato de que adicionar uma variável às equações de mínimos quadrados nos permitirá ajustar os dados de treino (embora não necessariamente os dados de teste) mais acuradamente. Podemos perceber que a diferença do r² ajustado é muito pequeno de um modelo para o outro (apenas 0.0398), o que nos fornece evidências adicionais de que as seis variáveis retiradas do modelo não são boas preditoras.

O RSE é o <i>erro padrão dos desvios</i> ou <i>erro padrão da regressão</i>. Quanto menor o RSE, melhor é a previsão dada pelo modelo. Apesar do RSE do segundo modelo ser melhor do que o RSE do primeiro, devemos observar também os graus de liberdade, que para o segundo modelo são 285 e para o primeiro são 90. Então, a pequena diferença entre os RSEs dos modelos pode ser relevada considerando o aumento de 4 vezes mais graus de liberdade.

Também poderíamos comparar os p-valores das variáveis preditoras em ambos os modelos. Assumindo que um p-valor satisfatório é menor que 0.05, verificamos que das doze variáveis preditoras utilizadas no modelo 1, apenas 2 possuem um p-valor aceitável. Em contrapartida, todas as seis variáveis do modelo 2 possuem p-valores muito abaixo do treshold. Isso nos diz que no segundo modelo, todas as variáveis estão altamente relacionadas com a variável resposta, ao contrário do primeiro.

<li><b> Analise os plots de resíduos de cada variável e veja se algum (um ou mais) deles indica não aleatoriedade dos erros. </li></b>

Abaixo, apresentamos scatter plots dos resíduos para cada variável preditora.

```{r, fig.width=9, fig.height=6, echo=FALSE}
graduados.model.input <- na.omit(graduados.model.input)
graduados.model.input$residuals <- residuals(cra.model.fit)

variable.names <- c(names(graduados.model.input)[2:13], "residuals")
plotDF <- melt(graduados.model.input[, variable.names], id="residuals")

ggplot(plotDF, aes(x=value, y=residuals)) + 
  geom_point(color="slateblue") + facet_wrap(~ variable)
```

Analisando os plots dos resíduos de cada variável, identifica-se aleatoriedade em todos os gráficos e uma simetria dos pontos em torno do valor 0. Então, concluímos que nenhuma variável tende a superestimar ou subestimar a variável de resposta.

<li><b> Que período consegue explicar melhor o desempenho final (primeiro ou segundo)? </li></b>