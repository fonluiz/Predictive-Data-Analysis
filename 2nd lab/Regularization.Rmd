---
title: 'Parte 3: Predição'
author: "Luiz Fonseca"
date: "7 de dezembro de 2016"
output: html_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=F, echo = TRUE, set.seed(825), message=FALSE, warning=FALSE)

# setwd("/home/luiz/Faculdade/Predictive-Data-Analysis/2nd lab/")
```

Primeiro vamos carregar os dados e bibliotecas que serão utilizados.

```{r, results='hide'}
library(dplyr)
library(ggplot2)
library(reshape2)
library(caret)
library(leaps)

students.train.data <- read.csv("data/graduados_treino.csv")
students.test.data <- read.csv("data/graduados_teste.csv")

# set.seed(825) Para reproduzir os resultados
```

## Entendendo o problema e os dados

O objetivo deste exercício é construir modelos preditivos de regressão utilizando técnicas de regularização e seleção de variáveis para a predição do CRA baseados nas disciplinas do primeiro e segundo semestres. Os dados são sobre os alunos do Curso de Ciência da Computação da Universidade Federal de Campina Grande. Os dados fornecidos foram divididos em dados de treinos e de teste. Os dados de teste são cronologicamente posteriores aos dados de treino para que dessa forma podemos prever o "futuro" com base no passado.

## Preprocessamento dos dados
```{r}
preProcessModelInput <- function(dataframe) {
  # Renomea as colunas
  names(dataframe) <- c("matricula", "ano_formatura", "periodo_formatura",
                                "cod_disciplina", "disciplina", "creditos", "media")
  # Retira os valores NA das médias
  dataframe <- dataframe %>% 
  filter(!is.na(media))
  
  # Calcula o CRA de cada aluno
  dataframe.cra <- dataframe %>%
  group_by(matricula) %>%
  mutate(cra.contrb = media*creditos) %>%
  summarise(cra = round(sum(cra.contrb)/sum(creditos), 2))
  
  disciplinas.iniciais <- c(
  "Cálculo Diferencial e Integral I",
  "Álgebra Vetorial e Geometria Analítica",
  "Leitura e Produção de Textos",
  "Programação I",
  "Introdução à Computação",
  "Laboratório de Programação I",
  "Cálculo Diferencial e Integral II",
  "Matemática Discreta",
  "Programação II",
  "Teoria dos Grafos",
  "Fundamentos de Física Clássica",
  "Laboratório de Programação II"
  )
  
  # Transforma o dataframe em um formato ideal para ser utilizado como entrada do modelo
  dataframe <- dataframe %>%
  filter(disciplina %in% disciplinas.iniciais) %>%
  group_by(matricula,disciplina)  %>%
  filter(media == max(media)) %>%
  ungroup() %>%
  select(matricula,disciplina,media) %>% 
  mutate(disciplina = as.factor(gsub(" ",".",disciplina))) %>%
  dcast(matricula ~ disciplina, mean) %>%
  merge(dataframe.cra) %>%
  na.omit()
  
  return(dataframe)
}

students.train.data <- students.train.data %>% preProcessModelInput()
students.test.data <- students.test.data %>% preProcessModelInput()
```

## Atividades
<ol>
<li><b>Usando todas as variáveis disponíveis (disciplinas do primeiro e segundo período), use validação cruzada (nos dados de treino) para tunar um modelo de regressão Ridge. </b></li>

Será utilizado o pacote caret, que implementa funções para tunar modelos usando o método ridge, lasso ou outros. Será utilizada uma validação cruzada 10-fold.

<p>Explicação sobre a regressão Ridge:</p>
<p>A grande vantagem do método ridge é que através dele podemos diminuir a variância do modelo ao custo de um pequeno aumento no BIAS. O método ridge tende a aproximar os coeficientes das variáveis preditoras de 0, conforme o lambda aumenta. Isso diminui a flexibilidade do modelo, diminuindo também a variância, porém aumentando o BIAS. A ideia por trás da regressão Ridge é encontrar um lambda que gere um trade-off satisfatório entre BIAS e Variância.</p>

```{r}
# library(caret)
fitControl <- trainControl(method = "cv",
                           number = 10)

lambdaGrid <- expand.grid(lambda = 10^seq(10, -2, length=100))

ridge.fit <- train(form = cra ~.,
                   data = students.train.data %>% select(-matricula),
                   trControl = fitControl,
                   method = 'ridge',
                   tuneGrid = lambdaGrid,
                   preProcess = c('scale', 'center'),
                   na.action = na.omit)

ridge.fit
```

O melhor modelo gerado, levando em consideração o modelo que apresentou menor RMSE, foi o modelo cujo lambda é 0.1629751. O RMSE foi igual a 0.5666946 e o R² foi igual a 0.5831063 para o treinamento. É importante saber que esses valores podem variar um pouco a cada vez que rodamos o treino.

<b><li>Mesmo que o item acima mas usando um modelo de regressão Lasso. </b></li>

<p>Explicação sobre o método Lasso:</p>
<p>O método Lasso é uma recente alternativa à regressão Ridge. A desvantagem da Ridge é que ela utiliza todas as variáveis. No ridge, embora todos os coeficientes tendam a se aproximar de 0, todos sao utilizados. Na regressão Lasso, alguns coeficientes são forçados à exatamente 0, e isso significa que podemos descartar algumas variáveis. Essa é a grande vantagem do método Lasso em detrimento do método Ridge.</p>   

```{r}
lasso.fit <- train(
  form = cra ~ .,
  data = students.train.data %>% select(-matricula),
  method = 'lasso',
  preProc = c('scale', 'center'),
  trControl = fitControl
)
  
lasso.fit
```

O melhor modelo apontado pelo Lasso no treinamento possui um RMSE igual a 0.5380783 e um R² igual a 0.6531297. 

<b><li> Quais as variáveis mais importantes segundo o modelo de regressão Lasso? Alguma variável foi descartada? Quais? </b></li>

Vamos verificar se alguma variável preditora ficou com coeficiente exatamente 0. Em caso afirmativo, poderemos descartar essas variáveis.

```{r}
predict.enet(lasso.fit$finalModel, type='coefficients', s=lasso.fit$bestTune$fraction, mode='fraction')
```

Então, a regressão Lasso apontou que podemos descartar 3 variáveis do nosso modelo. São elas, Laboratório.de.Programação.I, Leitura.e.Produção.de.Textos e Programação.I. Podemos verificar quais variáveis são mais importantes no gráfico abaixo:

```{r}
ggplot(varImp(lasso.fit)) +
  geom_bar(stat="identity", fill="#56B4E9", colour="black") +
  labs(title="Importância de variáveis (Lasso)", y="Importância", x="Variável")
```


<b><li>Compare os dois modelos nos dados de teste em termos de RMSE.</b></li>

Agora, serão usados os dados de treino para termos uma noção melhor sobre o poder preditivo dos nossos modelos.

```{r}
rmse <- function(error) {
    sqrt(mean(error^2))
}

ridge.pred <- predict(ridge.fit, students.test.data)
ridge.rmse <- rmse(ridge.pred - students.test.data$cra)

lasso.pred <- predict(lasso.fit, students.test.data)
lasso.rmse <- rmse(lasso.pred - students.test.data$cra)

ridge.rmse
lasso.rmse
```

<p>Comparando os dois modelos nos dados de teste, temos que o método ridge apresentou um RMSE ligeiramente menor do que o método lasso, a saber, 0.4005705 (ridge) contra 0.4019459 (lasso). </p>

<p>De uma forma geral, o Lasso tem um comportamento bastante similar com a regressão ridge em termos de variância e BIAS. O Lasso produz resultados melhores do que o ridge em casos que somente poucos preditores têm coeficientes significantes e o restante possuem coeficientes muito próximos de ou iguais a zero. A regressão ridge obterá resultados melhores que a lasso em casos que a variável de resposta possui muitos preditores e todos com valores na mesma faixa. </p>

<b><li>Re-treine o melhor modelo (dessa vez nos dados de treino sem validação cruzada) e reporte o RMSE no teste.</b></li>

Vamos retreinar o modelo ridge sem utilizar a validação cruzada.

```{r}
ridge.fit.no.cv <- train(form = cra ~.,
                   data = students.train.data %>% select(-matricula),
                   method = 'ridge',
                   tuneGrid = lambdaGrid,
                   preProcess = c('scale', 'center'),
                   na.action = na.omit)

ridge.no.cv.pred <- predict(ridge.fit.no.cv, students.test.data)
ridge.no.cv.rmse <- rmse(ridge.no.cv.pred - students.test.data$cra)
ridge.no.cv.rmse
```

Sem o uso da validação cruzada, o RMSE teve uma queda desprezível. Isso acontece porquê a validação cruzada (cross validation) não altera em nada o resultado dos testes. A validação cruzada pode ser utilizada para estimar o erro de teste associado a um determinado método de aprendizado estatístico e com isso podemos melhor avaliar a performance do modelo gerado, ou selecionar um nível apropriado de flexibilidade.s

<b><li>Use ou tente melhorar o seu modelo para prever os dados de teste que disponibilizamos por meio da plataforma Kaggle:</b></li>


</ol>
